{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/remicastaing/Colab/blob/main/Copie_de_P3_Distilling_the_Knowledge_distillation_selon_exemple_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxttzfPo-ZHM",
        "outputId": "16281461-8879-4f80-bc4f-85eecd2b510a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting keras\n",
            "  Downloading keras-3.0.4-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.23.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.0)\n",
            "Collecting namex (from keras)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras) (0.1.8)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Installing collected packages: namex, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.0.4 namex-0.0.7\n"
          ]
        }
      ],
      "source": [
        "pip install keras --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hE2mRo8d-1Hp"
      },
      "outputs": [],
      "source": [
        "data_path=\"/content/drive/MyDrive/CNAM/RCP209/Projet - Distilling the Knowledge in a Neural Network/data/\"\n",
        "\n",
        "images_path=\"/content/drive/MyDrive/CNAM/RCP209/Projet - Distilling the Knowledge in a Neural Network/Rapport/Images/\"\n",
        "\n",
        "resnet50_model_file = \"resnet50-model-keras3.keras\"\n",
        "\n",
        "resnet18_model_file = \"ResNet18-81.keras\"\n",
        "\n",
        "input_shape = (32, 32, 3)\n",
        "classes = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDG8REGg_wiF"
      },
      "source": [
        "#1. Import des bibliothèque"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3iieHniAS9r"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "from keras import metrics\n",
        "\n",
        "from keras import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Lambda\n",
        "from keras.layers import concatenate\n",
        "from keras.regularizers import l2\n",
        "\n",
        "\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMLdq46jCRiw"
      },
      "source": [
        "#2. Definition fonction graphique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8oLsBklAag8"
      },
      "outputs": [],
      "source": [
        "def loss_accuracy_graph(history, nom_fichier):\n",
        "\n",
        "  history_dict = history.history\n",
        "  loss_values = history_dict['loss']\n",
        "  val_loss_values = history_dict['val_loss']\n",
        "\n",
        "  epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "  fig = plt.figure(figsize=(14, 4))\n",
        "\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(epochs, loss_values, 'bo', label=\"Entrainement\")\n",
        "  plt.plot(epochs, val_loss_values, 'b', label='Validation')\n",
        "  plt.title(\"Coût à l'entrainement et à la validation\")\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Coût')\n",
        "  plt.legend()\n",
        "\n",
        "  acc = history_dict['accuracy']\n",
        "  val_acc = history_dict['val_accuracy']\n",
        "\n",
        "  epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(epochs, acc, 'o', label=\"Entrainement\", c='orange')\n",
        "  plt.plot(epochs, val_acc, '-', label='Validation', c='orange')\n",
        "  plt.title(\"Précision à l'entrainement et à la validation\")\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Précision')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.savefig(images_path + nom_fichier + '.png')\n",
        "\n",
        "  with open(images_path + nom_fichier + '_hist', 'wb') as file_pi:\n",
        "    pickle.dump(history_dict, file_pi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7gKACvxCZbb"
      },
      "source": [
        "# 3. Import des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9Wvr4rnCc5u",
        "outputId": "d8c65b4d-5e97-4959-9a6c-a417c52850cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = preprocess_input(x_train)\n",
        "x_test = preprocess_input(x_test)\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q889hnApJu_r"
      },
      "source": [
        "#4. Import et modification du modèle professeur ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xED40zYeN8kD",
        "outputId": "b90dddae-6d0c-4671-8c73-8fb6acef6e64"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:394: UserWarning: Skipping variable loading for optimizer 'adam', because it has 458 variables whereas the saved optimizer has 34 variables. \n",
            "  trackable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "#import du modèle ResNet50 entrainé précédemment\n",
        "\n",
        "resnet50_model = keras.models.load_model(data_path + resnet50_model_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIdfCg1iguU0"
      },
      "source": [
        "#5. Définition du modèle ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeWhCDdohv-u"
      },
      "outputs": [],
      "source": [
        "def conv2d_bn(x, filters, kernel_size, weight_decay=.0, strides=(1, 1)):\n",
        "    layer = Conv2D(filters=filters,\n",
        "                   kernel_size=kernel_size,\n",
        "                   strides=strides,\n",
        "                   padding='same',\n",
        "                   use_bias=False,\n",
        "                   kernel_regularizer=l2(weight_decay)\n",
        "                   )(x)\n",
        "    layer = BatchNormalization()(layer)\n",
        "    return layer\n",
        "\n",
        "\n",
        "def conv2d_bn_relu(x, filters, kernel_size, weight_decay=.0, strides=(1, 1)):\n",
        "    layer = conv2d_bn(x, filters, kernel_size, weight_decay, strides)\n",
        "    layer = Activation('relu')(layer)\n",
        "    return layer\n",
        "\n",
        "\n",
        "def ResidualBlock(x, filters, kernel_size, weight_decay, downsample=True):\n",
        "    if downsample:\n",
        "        # residual_x = conv2d_bn_relu(x, filters, kernel_size=1, strides=2)\n",
        "        residual_x = conv2d_bn(x, filters, kernel_size=1, strides=2)\n",
        "        stride = 2\n",
        "    else:\n",
        "        residual_x = x\n",
        "        stride = 1\n",
        "    residual = conv2d_bn_relu(x,\n",
        "                              filters=filters,\n",
        "                              kernel_size=kernel_size,\n",
        "                              weight_decay=weight_decay,\n",
        "                              strides=stride,\n",
        "                              )\n",
        "    residual = conv2d_bn(residual,\n",
        "                         filters=filters,\n",
        "                         kernel_size=kernel_size,\n",
        "                         weight_decay=weight_decay,\n",
        "                         strides=1,\n",
        "                         )\n",
        "    out = layers.add([residual_x, residual])\n",
        "    out = Activation('relu')(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "def ResNet18(weight_decay=1e-4):\n",
        "    input = Input(shape=input_shape)\n",
        "    x = input\n",
        "    x = conv2d_bn_relu(x, filters=64, kernel_size=(3, 3), weight_decay=weight_decay, strides=(1, 1))\n",
        "\n",
        "    # # conv 2\n",
        "    x = ResidualBlock(x, filters=64, kernel_size=(3, 3), weight_decay=weight_decay, downsample=False)\n",
        "    x = ResidualBlock(x, filters=64, kernel_size=(3, 3), weight_decay=weight_decay, downsample=False)\n",
        "    # # conv 3\n",
        "    x = ResidualBlock(x, filters=128, kernel_size=(3, 3), weight_decay=weight_decay, downsample=True)\n",
        "    x = ResidualBlock(x, filters=128, kernel_size=(3, 3), weight_decay=weight_decay, downsample=False)\n",
        "    # # conv 4\n",
        "    x = ResidualBlock(x, filters=256, kernel_size=(3, 3), weight_decay=weight_decay, downsample=True)\n",
        "    x = ResidualBlock(x, filters=256, kernel_size=(3, 3), weight_decay=weight_decay, downsample=False)\n",
        "    # # conv 5\n",
        "    x = ResidualBlock(x, filters=512, kernel_size=(3, 3), weight_decay=weight_decay, downsample=True)\n",
        "    x = ResidualBlock(x, filters=512, kernel_size=(3, 3), weight_decay=weight_decay, downsample=False)\n",
        "    x = AveragePooling2D(pool_size=(4, 4), padding='valid')(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(classes, name=\"last_dense\")(x)\n",
        "    output = Activation('softmax', name=\"output\")(x)\n",
        "\n",
        "\n",
        "    model = Model(input, output, name='ResNet18_temp')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWY4WbSRpSce"
      },
      "source": [
        "#6. Préparation des modèles élève et profsseur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-L1MDyDq69g"
      },
      "outputs": [],
      "source": [
        "def preparation_etudiant(model):\n",
        "\n",
        "  input_tensor = model.input\n",
        "\n",
        "  output = model.get_layer(\"output\").output\n",
        "\n",
        "  output_digits = model.get_layer(\"last_dense\").output\n",
        "#  temperature_layer = Lambda(lambda x: x / temperature, name='temperature_T' + str(temperature))(last_dense)\n",
        "#  output_tempere = Activation('softmax', name='output_tempere')(temperature_layer)\n",
        "\n",
        "  etudiant = Model(input_tensor, [output, output_digits], name='ResNet18_temperere')\n",
        "\n",
        "  return etudiant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0hCSrr59dFK"
      },
      "outputs": [],
      "source": [
        "def loss_tempere(temperature) :\n",
        "\n",
        "    return lambda y_D10_digits, y_pred_digits : losses.categorical_crossentropy(Activation('softmax')(y_D10_digits/temperature), Activation('softmax')(y_pred_digits/temperature))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9KHz6_Ny4zo"
      },
      "outputs": [],
      "source": [
        "def preparation_professeur(model):\n",
        "\n",
        "  input_tensor = model.input\n",
        "\n",
        "  last_dense = model.get_layer(\"last_dense\").output\n",
        "\n",
        "  professeur = Model(input_tensor, last_dense, name='ResNet50_digits')\n",
        "\n",
        "  return professeur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn8wRCt3Ip6O"
      },
      "outputs": [],
      "source": [
        "professeur = preparation_professeur(resnet50_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoGUKHNSIuxK",
        "outputId": "5fc7556f-956e-4c2d-9830-301b845e4adb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 90ms/step\n"
          ]
        }
      ],
      "source": [
        "digits = professeur.predict(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JiONc4xs6Cs",
        "outputId": "30a03aee-2cae-419b-f5fe-8d1d6cb43b2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 70ms/step - last_dense_kl_divergence: 2.5023 - loss: 2.0807 - output_accuracy: 0.4533\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 61ms/step - last_dense_kl_divergence: 2.3224 - loss: 1.3876 - output_accuracy: 0.7115\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 61ms/step - last_dense_kl_divergence: 3.3375 - loss: 1.2322 - output_accuracy: 0.7747\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 61ms/step - last_dense_kl_divergence: 4.3081 - loss: 1.1540 - output_accuracy: 0.8120\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 61ms/step - last_dense_kl_divergence: 5.2644 - loss: 1.1190 - output_accuracy: 0.8328\n",
            "Epoch 6/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 61ms/step - last_dense_kl_divergence: 6.3896 - loss: 1.0837 - output_accuracy: 0.8555\n",
            "Epoch 7/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 61ms/step - last_dense_kl_divergence: 7.2553 - loss: 1.0415 - output_accuracy: 0.8753\n",
            "Epoch 8/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 61ms/step - last_dense_kl_divergence: 8.1456 - loss: 1.0184 - output_accuracy: 0.8868\n",
            "Epoch 9/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 60ms/step - last_dense_kl_divergence: 9.3119 - loss: 0.9909 - output_accuracy: 0.9034\n",
            "Epoch 10/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 61ms/step - last_dense_kl_divergence: 10.1403 - loss: 0.9724 - output_accuracy: 0.9131\n"
          ]
        }
      ],
      "source": [
        "weight_decay = 1e-4\n",
        "temperature = 5\n",
        "alpha = 0.3\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "resnet18 = ResNet18( weight_decay=weight_decay)\n",
        "\n",
        "etudiant = preparation_etudiant(resnet18)\n",
        "\n",
        "etudiant.compile(optimizer='Adam',\n",
        "                loss=[losses.categorical_crossentropy, loss_tempere(temperature)],\n",
        "                loss_weights=[1-alpha, alpha],\n",
        "                metrics={'output' : ['accuracy'], 'last_dense': [metrics.KLDivergence()]})\n",
        "\n",
        "history = etudiant.fit(x_train, [y_train, digits],\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5JPmwF2ya4B"
      },
      "source": [
        "#7. Preparation données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bL3CMQ7Dyed_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7KtFgSEQXwR"
      },
      "source": [
        "#8. Entrainement par distillation du savoir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWFEWVs53BoY",
        "outputId": "c55c6157-0b7b-4b72-da49-4f636eb32c53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 26ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step\n"
          ]
        }
      ],
      "source": [
        "weight_decay = 1e-4\n",
        "\n",
        "etudiant = ResNet18( weight_decay=weight_decay)\n",
        "\n",
        "alembic = Alembic(etudiant, resnet50_model)\n",
        "\n",
        "alembic.load_data(x_train, x_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "OKC1-alW5Iri",
        "outputId": "12fca429-6f97-485f-f62d-fbea53197678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "(None, 10)\n",
            "(None, 10)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(None, 10), output.shape=(None, 10)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-6f976d02209e>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0malembic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-0d87ec65ec7f>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, batch_size, epochs, verbose)\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     super().fit(self.x_train, self.y_train_distillation,\n\u001b[0m\u001b[1;32m     47\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-0d87ec65ec7f>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, x, y, y_pred, sample_weight, allow_empty)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0metudiant_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0metudiant_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     distillation_loss = self.distillation_loss_fn(\n",
            "\u001b[0;31mValueError\u001b[0m: Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(None, 10), output.shape=(None, 10)"
          ]
        }
      ],
      "source": [
        "batch_size=64\n",
        "epochs = 100\n",
        "\n",
        "alembic.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    etudiant_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=0.1,\n",
        "    temperature=10,\n",
        ")\n",
        "\n",
        "alembic.fit(epochs=epochs, batch_size=batch_size, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2qtzr5GhsWP"
      },
      "source": [
        "#9. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbB9WSyrhvCy"
      },
      "outputs": [],
      "source": [
        "def resnet18_sans_temperature(model):\n",
        "  multiply_layer = Lambda(lambda x: x / temperature)\n",
        "  softmax_layer = Activation('softmax')\n",
        "\n",
        "  input_tensor = model.input\n",
        "  output_tensor = model.get_layer(\"last_dense\").output\n",
        "\n",
        "\n",
        "  new_output_tensor = Activation('softmax')(output_tensor)\n",
        "\n",
        "  model = Model(input_tensor, new_output_tensor, name='ResNet18_sans_temp')\n",
        "\n",
        "  model.compile(optimizer='Adam',\n",
        "                       loss=losses.categorical_crossentropy,\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS-QbGAmByh8",
        "outputId": "a6c5b94c-913e-4aa0-a06f-36aa71999bc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 6ms/step - loss: 1.1237 - accuracy: 0.8369\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.1237249374389648, 0.836899995803833]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resnet18_sans_temperature(resnet18_soft_model).evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GR4lIiqzvI_"
      },
      "source": [
        "#Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehmE2dqg0SWH"
      },
      "outputs": [],
      "source": [
        "restnet50_soft = resnet50_tempere(resnet50_model, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "AJdXSvWnzyx2",
        "outputId": "9f24f894-8956-4b60-c461-7fe9435adf57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 44/196 [=====>........................] - ETA: 55:38 - loss: 2.2331 - accuracy: 0.3231"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-909760daaa26>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                        metrics=['accuracy'])\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m history = resnet18_model.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m     15\u001b[0m                              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "weight_decay = 1e-4\n",
        "lr = 1e-1\n",
        "num_classes = 10\n",
        "batch_size=256\n",
        "\n",
        "callback = keras.callbacks.EarlyStopping(monitor='loss', mode='min', min_delta=0.01, baseline=0.2, restore_best_weights=True)\n",
        "\n",
        "resnet18_model = ResNet18_tempere( weight_decay=weight_decay, temperature=2)\n",
        "opt = optimizers.SGD(learning_rate=lr, momentum=0.9, nesterov=False)\n",
        "resnet18_model.compile(optimizer=opt,\n",
        "                       loss=losses.categorical_crossentropy,\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "history = resnet18_model.fit(x_train, y_train,\n",
        "                             epochs=100,\n",
        "                             batch_size=batch_size,\n",
        "                             validation_data=(x_test, y_test),\n",
        "                             callbacks=[callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wA9OvTEq1BZl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2500tOMU_aI"
      },
      "outputs": [],
      "source": [
        "class Alembic(keras.Model):\n",
        "  def __init__(self, student_model, teacher_model):\n",
        "    super().__init__()\n",
        "    self.teacher_model = self.raccourcir(teacher_model)\n",
        "    self.student_model = self.raccourcir(student_model)\n",
        "\n",
        "  def raccourcir(self, model):\n",
        "    input_tensor = model.input\n",
        "    new_output_tensor = model.get_layer(\"last_dense\").output\n",
        "\n",
        "    model_raccourci = keras.models.Model(input_tensor, new_output_tensor)\n",
        "\n",
        "    return model_raccourci\n",
        "\n",
        "  def distillation_loss_fn(temperature, alpha):\n",
        "\n",
        "      # Extract the one-hot encoded values and the softs separately so that we can create two objective functions\n",
        "\n",
        "      def distillation_loss(y_true, y_D10_digits)\n",
        "\n",
        "        y_true, y_D50_softmax = y_true[: , :classes], y_true[: , classes:]\n",
        "\n",
        "        y_pred, y_pred_softs = y_pred[: , :classes], y_pred[: , classes:]\n",
        "\n",
        "        y_pred_soft = Activation('softmax')(y_pred)\n",
        "\n",
        "        y_D\n",
        "\n",
        "\n",
        "        output =\n",
        "\n",
        "        loss = alpha * losses.categorical_crossentropy(y_true,y_pred) + (1 - alpha) * losses.categorical_crossentropy(y_true_softs, y_pred_softs)\n",
        "\n",
        "      return distillation_loss\n",
        "\n",
        "\n",
        "\n",
        "  def compile(\n",
        "      self,\n",
        "      optimizer,\n",
        "      metrics,\n",
        "      student_loss_fn,\n",
        "      distillation_loss_fn,\n",
        "      alpha=0.1,\n",
        "      temperature=3,\n",
        "      ):\n",
        "\n",
        "    super().compile(optimizer=optimizer, metrics=metrics)\n",
        "    self.student_loss_fn = student_loss_fn\n",
        "    self.distillation_loss_fn = distillation_loss_fn\n",
        "    self.alpha = alpha\n",
        "    self.temperature = temperature\n",
        "\n",
        "  def load_data(self, x_train, x_test, y_train, y_test):\n",
        "\n",
        "\n",
        "\n",
        "    # Concatenation des données pour obetnir un vecteur de 10 + 10 comprenant la vérité vrai et la prediction du resnet50\n",
        "\n",
        "    self.x_train = x_train\n",
        "    self.x_test = x_test\n",
        "\n",
        "    self.y_train = y_train\n",
        "    self.y_test = y_test\n",
        "\n",
        "    self.y_train_digits = self.teacher_model.predict(x_train)\n",
        "    self.y_test_digits = self.teacher_model.predict(x_test)\n",
        "\n",
        "\n",
        "\n",
        "  def train(self, batch_size, epochs, verbose, temperature, alpha):\n",
        "\n",
        "    y_train_distillation = np.concatenate([y_train, self.y_train_digits / self.temperature], axis=1)\n",
        "    y_test_distillation =  np.concatenate([y_test, self.y_test_digits / self.temperature], axis =1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    super().fit(self.x_train, self.y_train_distillation,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(self.x_test, self.y_test_distillation))\n",
        "\n",
        "\n",
        "  def compute_loss(\n",
        "    self, x=None, y=None, y_pred=None, sample_weight=None, allow_empty=False\n",
        "    ):\n",
        "\n",
        "    y, y_softs = y[: , :classes], y[: , classes:]\n",
        "\n",
        "    print(y.shape)\n",
        "    print(y_pred.shape)\n",
        "    etudiant_loss = self.student_loss_fn(y, y_pred)\n",
        "\n",
        "    distillation_loss = self.distillation_loss_fn(\n",
        "      keras.ops.softmax(y_softs / self.temperature, axis=1),\n",
        "      keras.ops.softmax(y_pred / self.temperature, axis=1),\n",
        "      ) * (self.temperature**2)\n",
        "\n",
        "    loss = self.alpha * etudiant_loss + (1 - self.alpha) * distillation_loss\n",
        "    return loss\n",
        "\n",
        "  def call(self, x):\n",
        "    return self.etudiant(x)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1rChTIG8v6_aQvmpWClJClb5BM6JdMPZ0",
      "authorship_tag": "ABX9TyPzcubX+TvRqET9BIpZwkAo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}